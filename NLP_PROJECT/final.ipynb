{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 22:24:34.362824: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-29 22:24:35.008485: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-29 22:24:38.874680: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/pratyasa/NLP_EMOTION_DEPICTOR/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import tensorflow as tf\n",
    "from transformers import TFAutoModelForSequenceClassification, AutoTokenizer, AutoConfig\n",
    "from pywebio import start_server\n",
    "from pywebio.input import input, textarea\n",
    "from pywebio.output import put_text, put_html, put_buttons, put_image\n",
    "from pywebio.session import defer_call\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pywebio.output import put_text, put_html, put_buttons, put_image, put_table\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer and model configuration\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"fine_tuned_model\")\n",
    "config = AutoConfig.from_pretrained(\"fine_tuned_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 22:24:51.261842: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-29 22:24:51.263013: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"fine_tuned_model\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize recognizer\n",
    "recognizer = sr.Recognizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable to keep track of recording state\n",
    "is_recording = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize lists to store conversation outputs and distraction levels\n",
    "conversation_outputs = []\n",
    "predicted_emotions = []\n",
    "probability_distributions = []\n",
    "distraction_levels = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform speech recognition with customizable parameters\n",
    "def recognize_speech(sample_rate=44100, chunk_size=1024):\n",
    "    global is_recording\n",
    "    # Start recording if not already recording\n",
    "    if not is_recording:\n",
    "        is_recording = True\n",
    "        put_text(\"Speak\", \"Speak something...\")\n",
    "        \n",
    "        # Adjust microphone sample rate and chunk size\n",
    "        with sr.Microphone(sample_rate=sample_rate, chunk_size=chunk_size) as source:\n",
    "            # Adjust energy threshold dynamically\n",
    "            recognizer.adjust_for_ambient_noise(source)\n",
    "            # Listen for audio input\n",
    "            audio = recognizer.listen(source)\n",
    "\n",
    "        try:\n",
    "            # Recognize speech using Google Speech Recognition\n",
    "            user_input = recognizer.recognize_google(audio)\n",
    "            conversation_outputs.append(user_input)  # Save conversation output\n",
    "            handle_input(user_input)\n",
    "            generate_probability_distribution_graph() \n",
    "        except sr.UnknownValueError:\n",
    "            put_text(\"Sorry, I could not understand what you said.\")\n",
    "        except sr.RequestError as e:\n",
    "            put_text(\"Sorry, I could not request results from Google Speech Recognition service; {0}\".format(e))\n",
    "        \n",
    "        is_recording = False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to handle input and predict emotion\n",
    "def handle_input(user_input):\n",
    "    global probability_distributions\n",
    "    put_text(\"User:\", user_input)\n",
    "    # Tokenize the text\n",
    "    input_encoded = tokenizer(user_input, return_tensors='tf')\n",
    "\n",
    "    # Perform inference\n",
    "    outputs = model(input_encoded)\n",
    "\n",
    "    # Get predicted label and probabilities\n",
    "    logits = outputs.logits\n",
    "    probabilities = tf.nn.softmax(logits, axis=1).numpy()[0]\n",
    "    pred = tf.argmax(logits, axis=1).numpy()\n",
    "    predicted_label = pred[0]\n",
    "    predicted_emotions.append(predicted_label)\n",
    "    probability_distributions.append(probabilities)\n",
    "     # Display predicted emotion and probabilities\n",
    "    emojis = {\n",
    "        'sadness': 'üòî',\n",
    "        'joy': 'ü§ó',\n",
    "        'love': '‚ù§Ô∏è',\n",
    "        'anger': 'üò†',\n",
    "        'fear': 'üò®üò±',\n",
    "        'surprise': 'üòÆ'\n",
    "    }\n",
    "    labels = ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\n",
    "    predicted_emoji = emojis[labels[predicted_label]]\n",
    "\n",
    "    put_text(\"Chatbot:\", f\"The predicted emotion is: {labels[predicted_label]}{predicted_emoji}\")\n",
    "\n",
    "\n",
    "    # Calculate distraction level (for demonstration purposes, a random value is used)\n",
    "    distraction_level = np.random.uniform(0, 1)\n",
    "    distraction_levels.append(distraction_level)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to generate and display the probability distribution bar graph\n",
    "\n",
    "def generate_probability_distribution_graph():\n",
    "    global probability_distributions\n",
    "    # Plot probability distribution bar graph\n",
    "    \n",
    "    plt.rcParams['axes.facecolor'] = 'white'\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    labels = ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\n",
    "    probs = probability_distributions[-1] \n",
    "    colors = ['#9FB9C7', '#3D657A', '#C8E8FA', '#7DCFFB', '#677881', '#5B96A9']\n",
    "    bars = plt.bar(labels, probs, color=colors)\n",
    "    emoji_dict = {\n",
    "        'sadness': 'üòî',\n",
    "        'joy': 'ü§ó',\n",
    "        'love': '‚ù§Ô∏è',\n",
    "        'anger': 'üò†',\n",
    "        'fear': 'üò®üò±',\n",
    "        'surprise': 'üòÆ'\n",
    "    }\n",
    "\n",
    "    x_positions = [bar.get_x() + bar.get_width() / 2 for bar in bars]  # Center of each bar\n",
    "    y_positions = [bar.get_height() + 0.1 for bar in bars]  # Slightly above the bar\n",
    "    for x, y, label in zip(x_positions, y_positions, labels):\n",
    "        plt.text(x, y, emoji_dict[label], ha='center', va='bottom', fontsize=20)\n",
    "\n",
    "    plt.xlabel('Emotion')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.title('Probability Distribution of Emotions')\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save plot as image\n",
    "    plt.savefig('probability_distribution_graph.png')\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "    \n",
    "    # Display the generated image\n",
    "    put_image(open('probability_distribution_graph.png', 'rb').read(), width='80%')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate and display the distraction graph\n",
    "#\n",
    "\n",
    "def generate_distraction_graph():\n",
    "    global distraction_levels\n",
    "    # Plot distraction graph\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    turns = range(1, len(distraction_levels) + 1)\n",
    "    plt.plot(turns, distraction_levels, marker='o', linestyle='-',color='r')\n",
    "    plt.xlabel('Turns')\n",
    "    plt.ylabel('Distraction Level')\n",
    "    plt.title('Distraction Throughout Conversation')\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save plot as image\n",
    "    plt.savefig('distraction_graph.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Display the generated image\n",
    "    put_image(open('distraction_graph.png', 'rb').read(), width='80%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PyWebIO chatbot interface\n",
    "def chatbot_app():\n",
    "    put_html(\"<div style='background-color: white; padding: 20px;'> <h1>Emotion Depicter</h1> </div>\")\n",
    "    \n",
    "    def handle_text_input():\n",
    "        user_input = input(\"User:\", placeholder=\"Type here...\")\n",
    "        conversation_outputs.append(user_input)  # Save conversation output\n",
    "        handle_input(user_input)\n",
    "        generate_probability_distribution_graph()\n",
    "\n",
    "    def handle_speech_input():\n",
    "        recognize_speech()\n",
    "        generate_probability_distribution_graph()\n",
    "\n",
    "    def generate_graph():\n",
    "        generate_distraction_graph()\n",
    "       \n",
    "\n",
    "    put_buttons(['Please Write', 'üé§', 'Generate Distraction Graph'], onclick=[handle_text_input, handle_speech_input, generate_graph])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on all addresses.\n",
      "Use http://172.16.144.103:8086/ to access the application\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/pratyasa/NLP_EMOTION_DEPICTOR/final.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/pratyasa/NLP_EMOTION_DEPICTOR/final.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/pratyasa/NLP_EMOTION_DEPICTOR/final.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     start_server(chatbot_app, port\u001b[39m=\u001b[39;49m\u001b[39m8086\u001b[39;49m)\n",
      "File \u001b[0;32m~/NLP_EMOTION_DEPICTOR/.venv/lib/python3.11/site-packages/pywebio/platform/tornado.py:302\u001b[0m, in \u001b[0;36mstart_server\u001b[0;34m(applications, port, host, debug, cdn, static_dir, remote_access, reconnect_timeout, allowed_origins, check_origin, auto_open_webbrowser, max_payload_size, **tornado_app_settings)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[39mif\u001b[39;00m remote_access:\n\u001b[1;32m    300\u001b[0m     start_remote_access_service(local_port\u001b[39m=\u001b[39mport)\n\u001b[0;32m--> 302\u001b[0m tornado\u001b[39m.\u001b[39;49mioloop\u001b[39m.\u001b[39;49mIOLoop\u001b[39m.\u001b[39;49mcurrent()\u001b[39m.\u001b[39;49mstart()\n",
      "File \u001b[0;32m~/NLP_EMOTION_DEPICTOR/.venv/lib/python3.11/site-packages/tornado/platform/asyncio.py:205\u001b[0m, in \u001b[0;36mBaseAsyncIOLoop.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstart\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49masyncio_loop\u001b[39m.\u001b[39;49mrun_forever()\n",
      "File \u001b[0;32m/usr/lib/python3.11/asyncio/base_events.py:596\u001b[0m, in \u001b[0;36mBaseEventLoop.run_forever\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Run until stop() is called.\"\"\"\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[0;32m--> 596\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_running()\n\u001b[1;32m    597\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_coroutine_origin_tracking(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_debug)\n\u001b[1;32m    599\u001b[0m old_agen_hooks \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mget_asyncgen_hooks()\n",
      "File \u001b[0;32m/usr/lib/python3.11/asyncio/base_events.py:588\u001b[0m, in \u001b[0;36mBaseEventLoop._check_running\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_running\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    587\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_running():\n\u001b[0;32m--> 588\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mThis event loop is already running\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    589\u001b[0m     \u001b[39mif\u001b[39;00m events\u001b[39m.\u001b[39m_get_running_loop() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    590\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    591\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mCannot run the event loop while another loop is running\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11261/360626166.py:31: UserWarning: Glyph 129303 (\\N{HUGGING FACE}) missing from current font.\n",
      "/tmp/ipykernel_11261/360626166.py:34: UserWarning: Glyph 129303 (\\N{HUGGING FACE}) missing from current font.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    start_server(chatbot_app, port=8086)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
