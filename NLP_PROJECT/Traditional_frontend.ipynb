{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1mMDFYOvDiOvK1uBsmBFSlT78fqlbBtec","authorship_tag":"ABX9TyNC185QkGet9PQugfTASw8o"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install SpeechRecognition"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UQfh1im834mj","executionInfo":{"status":"ok","timestamp":1713471755270,"user_tz":-330,"elapsed":9427,"user":{"displayName":"Aditi Goel","userId":"13470766987512851860"}},"outputId":"d9f6555b-0f01-4b3a-a5a0-a1e25fb4d6bc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting SpeechRecognition\n","  Downloading SpeechRecognition-3.10.3-py2.py3-none-any.whl (32.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.31.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2024.2.2)\n","Installing collected packages: SpeechRecognition\n","Successfully installed SpeechRecognition-3.10.3\n"]}]},{"cell_type":"code","source":["!pip install pywebio"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vFrnvc0O4Bhn","executionInfo":{"status":"ok","timestamp":1713471793701,"user_tz":-330,"elapsed":8742,"user":{"displayName":"Aditi Goel","userId":"13470766987512851860"}},"outputId":"4ad645bf-f8bd-4c3a-c8a6-c40ee9a81f9f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pywebio\n","  Downloading pywebio-1.8.3.tar.gz (500 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/500.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/500.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m491.5/500.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m500.9/500.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.10/dist-packages (from pywebio) (6.3.3)\n","Collecting user-agents (from pywebio)\n","  Downloading user_agents-2.2.0-py3-none-any.whl (9.6 kB)\n","Collecting ua-parser>=0.10.0 (from user-agents->pywebio)\n","  Downloading ua_parser-0.18.0-py2.py3-none-any.whl (38 kB)\n","Building wheels for collected packages: pywebio\n","  Building wheel for pywebio (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pywebio: filename=pywebio-1.8.3-py3-none-any.whl size=509502 sha256=86da2cbbb8e5589157e99e539947c4cc4f69a7527b3f390e2ad41bf116764ccf\n","  Stored in directory: /root/.cache/pip/wheels/fa/72/9f/d0b62ad82e222e5ea96c1fdf07fb86a3ea667da6190a1aca16\n","Successfully built pywebio\n","Installing collected packages: ua-parser, user-agents, pywebio\n","Successfully installed pywebio-1.8.3 ua-parser-0.18.0 user-agents-2.2.0\n"]}]},{"cell_type":"code","source":["import nltk"],"metadata":{"id":"adpLe-FB40fG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B3keNsnX48Bb","executionInfo":{"status":"ok","timestamp":1713472017143,"user_tz":-330,"elapsed":1263,"user":{"displayName":"Aditi Goel","userId":"13470766987512851860"}},"outputId":"233fc230-d4a8-4aa3-c20f-452af0414006"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TKh23Qni3CZr"},"outputs":[],"source":["import speech_recognition as sr\n","from pywebio import start_server\n","from pywebio.input import input, textarea\n","from pywebio.output import put_text, put_html, put_buttons\n","from pywebio.session import defer_call\n","import pickle\n","import pandas as pd\n","import re\n","from nltk import word_tokenize\n","from nltk.stem import PorterStemmer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from keras.preprocessing.text import Tokenizer\n","\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import load_model\n","import numpy as np"]},{"cell_type":"code","source":["# Define the preprocess_and_tokenize function\n","def preprocess_and_tokenize(data):\n","    data = re.sub(\"(<.*?>)\", \"\", data)  # Remove html markup\n","    data = re.sub(r'http\\S+', '', data)  # Remove urls\n","    data = re.sub(r\"(#[\\d\\w\\.]+)\", '', data)  # Remove hashtags\n","    data = re.sub(r\"(@[\\d\\w\\.]+)\", '', data)  # Remove @names\n","    data = re.sub(\"(\\\\W|\\\\d)\", \" \", data)  # Remove punctuation and non-ascii digits\n","    data = data.strip()  # Remove whitespace\n","    data = word_tokenize(data)  # Tokenization with nltk\n","    porter = PorterStemmer()  # Stemming with nltk\n","    stem_data = [porter.stem(word) for word in data]\n","    return stem_data"],"metadata":{"id":"4vaCeeAk4Sh2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load TF-IDF SVM model and TF-IDF vectorizer\n","tfidf_svm_model = pickle.load(open('/content/drive/MyDrive/NLP_PROJECT/models/tfidf_svm.sav', 'rb'))\n","df_train = pd.read_csv('/content/drive/MyDrive/NLP_PROJECT/Train.csv')\n","vectorizer = TfidfVectorizer(tokenizer=preprocess_and_tokenize, sublinear_tf=True, norm='l2', ngram_range=(1, 2))\n","vectorizer.fit(df_train['Text'].tolist())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":390},"id":"4deUp4604dU8","executionInfo":{"status":"ok","timestamp":1713472086165,"user_tz":-330,"elapsed":19457,"user":{"displayName":"Aditi Goel","userId":"13470766987512851860"}},"outputId":"c316853b-aa0d-4c99-ec6b-4d0637bec139"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-11-1ee0ac1ea69c>:2: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n","  tfidf_svm_model = pickle.load(open('/content/drive/MyDrive/NLP_PROJECT/models/tfidf_svm.sav', 'rb'))\n","/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator TfidfTransformer from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n","https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n","https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LinearSVC from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n","https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n","https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["TfidfVectorizer(ngram_range=(1, 2), sublinear_tf=True,\n","                tokenizer=<function preprocess_and_tokenize at 0x797e9c401360>)"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(ngram_range=(1, 2), sublinear_tf=True,\n","                tokenizer=&lt;function preprocess_and_tokenize at 0x797e9c401360&gt;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(ngram_range=(1, 2), sublinear_tf=True,\n","                tokenizer=&lt;function preprocess_and_tokenize at 0x797e9c401360&gt;)</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# Load CNN model and tokenizer\n","cnn_model = load_model('/content/drive/MyDrive/NLP_PROJECT/models/cnn_w2v.h5')\n","tokenizer_cnn = Tokenizer()\n","tokenizer_cnn.fit_on_texts(df_train['Text'].tolist())"],"metadata":{"id":"DwwJrAFL5X6W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load LSTM model and tokenizer\n","lstm_model = load_model('/content/drive/MyDrive/NLP_PROJECT/models/biLSTM_w2v.h5')\n","tokenizer_lstm = Tokenizer()\n","tokenizer_lstm.fit_on_texts(df_train['Text'].tolist())"],"metadata":{"id":"dTkuLBbr3BI5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define emotion labels\n","class_names = ['joy', 'sadness', 'fear', 'anger', 'surprise', 'neutral', 'disgust', 'shame', 'guilt']"],"metadata":{"id":"V7dr8lhQ3MMS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def handle_input(user_input):\n","    put_text(\"User:\", user_input)\n","\n","    # Preprocess user input for TF-IDF SVM model\n","    user_input_tfidf = ' '.join(preprocess_and_tokenize(user_input))\n","    # Preprocess user input for CNN model\n","    sequence_cnn = tokenizer_cnn.texts_to_sequences([user_input])\n","    padded_sequence_cnn = pad_sequences(sequence_cnn, maxlen=500)\n","    # Preprocess user input for LSTM model\n","    sequence_lstm = tokenizer_lstm.texts_to_sequences([user_input])\n","    padded_sequence_lstm = pad_sequences(sequence_lstm, maxlen=500)\n","\n","    # Predictions\n","    prediction_tfidf = tfidf_svm_model.predict([user_input_tfidf])[0]\n","    prediction_cnn = cnn_model.predict(padded_sequence_cnn)[0]\n","    prediction_lstm = lstm_model.predict(padded_sequence_lstm)[0]\n","\n","    # Combine predictions using weighted average\n","    combined_pred = (0.7 * prediction_tfidf + 0.756 * prediction_cnn + 0.66 * prediction_lstm) / (0.7 + 0.756 + 0.66)\n","\n","    # Get the predicted label\n","    predicted_label_index = np.argmax(combined_pred)\n","    predicted_label = class_names[predicted_label_index]\n","\n","    put_text(\"Combined Prediction:\", predicted_label)\n"],"metadata":{"id":"ForsEhp03TJs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Global variable to track the state of recording\n","is_recording = False\n","\n","# Function to handle speech input\n","def handle_speech_input():\n","    global is_recording\n","\n","    if not is_recording:\n","        start_recording()\n","    else:\n","        stop_recording()\n","\n","def start_recording():\n","    global is_recording\n","    is_recording = True\n","\n","    recognizer = sr.Recognizer()\n","\n","    # Display the microphone prompt\n","    put_text(\"Speak\", \"Speak something...\")\n","\n","    with sr.Microphone() as source:\n","        audio = recognizer.listen(source)\n","        put_text(\"Processing...\")\n","\n","    try:\n","        user_input = recognizer.recognize_google(audio)\n","        handle_input(user_input)\n","    except sr.UnknownValueError:\n","        put_text(\"Sorry, I could not understand what you said.\")\n","    except sr.RequestError as e:\n","        put_text(\"Sorry, I could not request results from Google Speech Recognition service; {0}\".format(e))\n","\n","    is_recording = False\n","\n","# Function to stop recording\n","def stop_recording():\n","    global is_recording\n","    is_recording = False"],"metadata":{"id":"nIskPYLG3cOH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to define the chatbot app\n","def chatbot_app():\n","    put_html(\"<div style='background-color: white; padding: 20px;'> <h1>Emotion Depicter</h1> </div>\")\n","    put_buttons(['Please Write', '🎤'], onclick=[handle_text_input, handle_speech_input])"],"metadata":{"id":"ApOTaOP33lvZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Start the server\n","if __name__ == \"__main__\":\n","    start_server(chatbot_app, port=8086)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"et3FxPMG5t7c","executionInfo":{"status":"error","timestamp":1713454956376,"user_tz":-330,"elapsed":621,"user":{"displayName":"Aditi Goel","userId":"13470766987512851860"}},"outputId":"7e2ff62b-467f-47ee-ce90-cf207f7fccb5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Running on all addresses.\n","Use http://172.28.0.12:43395/ to access the application\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"This event loop is already running","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-d7146a1a30d8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Start the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mstart_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchatbot_app\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pywebio/platform/tornado.py\u001b[0m in \u001b[0;36mstart_server\u001b[0;34m(applications, port, host, debug, cdn, static_dir, remote_access, reconnect_timeout, allowed_origins, check_origin, auto_open_webbrowser, max_payload_size, **tornado_app_settings)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mstart_remote_access_service\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_port\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0mtornado\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mioloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIOLoop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masyncio_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_forever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/asyncio/base_events.py\u001b[0m in \u001b[0;36mrun_forever\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;34m\"\"\"Run until stop() is called.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_coroutine_origin_tracking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_debug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/asyncio/base_events.py\u001b[0m in \u001b[0;36m_check_running\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'This event loop is already running'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m             raise RuntimeError(\n","\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running"]}]}]}